\documentclass[]{article}
%opening
\title{Design Document}
\author{Alex Miller}
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}
\setcounter{secnumdepth}{0}
\usepackage{cancel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[ruled,vlined, linesnumbered]{algorithm2e}
\DontPrintSemicolon


\begin{document}
	\maketitle
	

\section{Modules, data structures, interfaces, invariants:}
Our code base will consist of the following modules:
\begin{itemize}
	\item The highest ranked modules containing C code will be three files, one called serial.c, another called parallel.c, and a third called serial\_queue.c
	\begin{itemize}
		\item These modules represent our serial, parallel, and serial-queue implementations of our checksum generating scheme
		\item All will take in the following input parameters: $<n>$ $<T>$ $<W>$ $<D>$ $<s>$ $<-cue>$ where:
		\begin{itemize}
			\item $<n>$ : How many sources should we use?
			\item $<T>$ : How many packets per source should we ask for?
			\item $<W>$ : What is the expected work of one packet?
			\item $<D>$ : How deep should our Lamport queues be (if an implementation supports their use)
			\item $<s>$ : A seed number to use throughout the programs runtime. This variable will correspond to what trial we are currently running.
			\item $<-cue>$ : This should be a flag; each character represents what type of packet extraction method we should utilize ($c$ is for constant, $u$ is for uniform, $e$ is for exponential)
		\end{itemize}
		\item We will be able to reference these files in our testing script (to be described later), simplifying our automated testing routines
		\item Each file will describe the following workflow:
		\begin{enumerate}
			\item Using user input, they will create the specified packet generator. Call this generator $packet\_gen$. It has $n$ sources, a median work value of $W$, and utilizes the seed $s$. 
			\item They will also bind the specified method of extracting packets from $packet\_gen$ to a pointer desginated $packet\_method$. 
			\item Lastly, they will allocate a 2D array with enough space to hold the values of all checksums to be generated. Call this array $res$
			\item They will then pass $packet\_gen$, $packet\_method$, $res$, as well as any necessary variables to one of two methods. The first will be known as chksum\_serial.c and the second chksum\_parallel.c. We will discuss the details of these functions in the context of their own modules. The first of these methods will be used by serial.c, while the second will be used by parallel.c and serial\_queue.c.
			\item These methods will be responsible for calculating the checksums for packets generated by $packet\_gen$ using $packet\_method$. They will also be the methods who's runtime we will measure to determine performance. Call this runtime measurement $<time>$
			\item These methods will also be writing the checksums they generate  to $res$. We will discuss how this is done in more detail later.
			\item These files will, finally, use the contents of $res$ in order to output verifiable results. For a given trial number, and for all $n$ sources, will write a file called $res/<n>\_<T>\_<W>\_<D>\_<s>\_<-cue>\_<time>$ which contains the list of $T$  checksums generated for a specified source, using a specified seed $s$. We will use these files to compare results of serial.c, parallel.c, and serial\_queue.c in order to judge correctness.
		\end{enumerate}
	\end{itemize}
	\item chksum.c
	\begin{itemize}
		\item This module will describe chksum\_serial() and chksum\_parallel, the methods that will bs used by serial.c, parallel.c, and serial\_queue.c
		\item chksum\_serial()
		\begin{itemize}
			\item Input: In addition to $packet\_gen$, $packet\_method$, and $res$ this function will also take in the values $n$ and $T$
			\item This method simply loops through $T$ packets for $n - 1$ sources, utilizing $packet\_method$ to extract new packets from $packet\_gen$
			\item $\forall i \in [n - 1], j \in [T]$ the method generates a checksum for the $j$-th packet of source $i$. This value is written to $res[i][j]$
		\end{itemize}
		\item chksum\_parallel()
		\begin{itemize}
			\item Input: In addition to $packet\_gen$, $packet\_method$, and $res$ this function will also take in the values $n$, $T$, $D$, as well as a new value $<p>$. $p$ describes how many worker threads should be used to generate checksums. When called by parallel.c, $p = n - 1$. When this method is called by serial\_queue.c, $p = 1$.
			\item This method will begin by allocating space for $p$ instances of the $queue\_t$ objects with depth $D$ (see next section for details on $queue\_t$). Call the thread that does this allocation $t_d$
			\item $t_d$ will create $p$ threads and bind each thread to a $queue\_t$ instance. Each thread $t$ will operate on it's queue $q$ in the following manner:
			\begin{itemize}
				\item $t$ will need to keep track of two values: $n$ and $T$. $n$ is set by $t_d$ for each thread $t$; it represents for what source index $t$ is generating checksums. $T$ is a counter maintained by $t$; initially $T = 0$.
				\item While $q.done == false$ and $q.isEmpty() == false$:
				\item If $q.isEmpty()$, $t$ will wait until it contains data
				\item Otherwise, $t$ will call $q.dequeu()$ and generate a checksum for the $Packet_t$ instance it extracts. More on how this instance is placed in $q$ in a second.
				\item Once the checksum is generated, $t$ stores the result at $res[n][T]$ and increments $T$ by 1.
				\item Once $q.done == true$ and $q.isEmpty() == true$, $t$ should return.
			\end{itemize}
			\item Meanwhile, as each thread $t$ is operating on its queue $q_t$, $t_d$ is looping through $T$ packets for $n - 1$ and acting accordingly:
			\begin{itemize}
				\item Since each thread is fixed to a given source, $t_d$ must be responsible for populating each thread's queue with packets from a singular source. What we must keep in mind is that there might be more sources than threads (in the case of serial\_queue.c) and the number of packets we can generate at any one time is limited by the depth $D$ of our $queue\_t$ objects.
				\item Therefore, I propose the following loop structure: $\forall t \in [p],$ let $q_t$ designate a Queue object bound to the thread $t$, let $n_t$ designate the source for which $t$ is generating checksums, completely fill $q_t$ with packets generated using $packet\_method$ from source $n_t$. Once this queue is full, move on to the next thread and do the same thing. Keep looping through all active threads like this until $t_d$ has written $T$ total packets to each $q_t$, at which point $t_d$ should $write(q_t.done = true)$.
				\item At this point, there may or may not be more sources for which we still must generate checksums; we take as many threads as we need (bounded by $p$ at a time) and utilize the above mentioned strategy for the remaining sources.
			\end{itemize}
			\item In this way, we are able to split the work of generating checksums of $T$ packets each from $n - 1$ sources among $p$ worker threads.
			\item Invariants:
			\begin{itemize}
				\item Each thread $t$ computes the checksum of the $i$th packet from source $n_t$ before computing the $i + 1$th packet from source $n_t$
				\item $t_d$ never writes a packet to a queue that is full
				\item Each thread $t$ does not return until it has generated all $T$ checksum for a given source $n_t$
			\end{itemize}
		\end{itemize}
	\end{itemize}
	\item queue.c
	\begin{itemize}
		\item This module will describe the construction and functionality of a $queue\_t$ object, containing the following attributes and utilizing the following methods:
		\item Attributes:
		\begin{itemize}
			\item $D$ : a specified depth
			\item $Q$ : a Lamport queue with depth $D$
			\item $T$ : an integer designating how many packets have been queued so far in $Q$. This is initially set to 0.
			\item $done$ : a boolean designating whether or not we should keep reading from $Q$. This is initially set to $false$
		\end{itemize}
		\item Methods:
		\begin{itemize}
			\item $enq(T x)$ : queue a value $x$ of type $T$ in $Q$. Throw an exception if $Q$ already contains $D$ entries
			\item $deq()$ : dequeue the next value from $Q$. Throw an exception if $Q$ contains no entries
			\item $isEmpty$ : returns $true$ is $Q$ does not contain any data, false if otherwise
			\item $isFull$ : returns $true$ is $Q$ is full of data, false if otherwise
		\end{itemize}
	\end{itemize}
	\item test\_script.sh
	\begin{itemize}
		\item This testing script will consist of a shell script that utilizes serial.c, parallel.c, and serial\_queue.c.
		\item Because all three aforementioned executables record their resultant checksums in text files, this script can use these modules to generate experimental data and then organize that data in appropriately named folders. I can use this capability to automatically run and format my experiments using as many trials as I want.
	\end{itemize}
All in all, my code can be said to contain four modules: the first level describes the serial, parallel, and serial-queue implementations specified in the assignment, the second describes serial and parallel implementations of computing checksums of $T$ packets from $n -1$ sources, the third describes the $queue\_t$ object that is needed for the parallel implementation, and the last level describes an automated testing structure that will generate and format my data.
\end{itemize}

\section{Test plan:} 
Initially I will need to test my implementation of serial.c, which in turn will require I test the following capabilities:
\begin{enumerate}
	\item Using the packet generator to generate different streams of input to chksum\_serial.c; I will know I am doing this successfully when I am able to deterministically print output at the command line using all three packet retrieval methods specified in the assignment. I can verify whether or not I am able to do this by testing output for sufficiently small values of $n$, $T$, $W$ and predetermined seed value $s$.
	This should count as a robust test on the grounds that deterministic output from these random functions using predetermined seed values should indicate that I am using these functions correctly or, at the very least generating usable inputs for my methods described in chksum.c
	\item Using chksum\_serial.c to generate checksums for $T$ packets from $n - 1$ sources; I will know that I am doing this successfully if I am able to deterministically output checksums at the command line using all three packet retrieval methods specified in the assignment. I can verify whether or not I am able to do this by testing output for sufficiently small values of $n$, $T$, $W$ and predetermined seed value $s$. This strategy holds because the implementation of chksum\_serial should be sufficiently trivial to implement and infer correctness for.
	\item Using the contents of $res$ in order to craft readable output in the form of text files; Once I am sure that chksum\_serial() works, I can use its output to verify that I am writing results to text files correctly
\end{enumerate}
Once I have demonstrated to myself an ability to generate checksums and record results using my serial implementation, I can use said results from my serial implementation to verify those of my parallel implementation. More specifically, I know these results should be equal for a given set of inputs for a given source given the uniformity of our seed variable within a given trial. Moreover, since threads in my parallel implementation record results in the order in which packets for a given source are generated, we know that our representation of results in text files should be equivalent across both serial and parallel implementations.
\\\\
test\_script.sh can utilize this equality of results across implementations to check that our results are being generated correctly across implementations and trials; it can do this by comparing the text files generated by chksum\_serial and chksum\_parallel and raising an error on the appearance of any discrepancies.
\\\\
As to the correctness of my $queue\_t$ declaration; whether or not this declaration is correct will be inferred from performance. Lamport queues are sufficiently well-known and easy to implement. The remaining methods and attributes of the $queue\_t$ data should also be easy to verify. We will therefore take an absence of compile errors and verifiable correctness of results to infer the correctness of this data structure as well.

\section{Expected Performance (Performance Hypotheses):} 
\subsection{Parallel Overhead:}
I expect to see slowdown of serial\_queue.c in relation to serial.c due to the extra overhead of allocating space for our singular Lamport queue and spawning an extra thread to calculate all of our checksums. Of course, however, this slowdown will be dwarfed or otherwise obscured by increasingly large values of $n$, $T$, and $W$; larger values for $n$ and $T$ imply that we will have more checksums to calculate and larger values of $W$ imply that each checksum will require more work. Therefore, for larger values of $n$, $T$, and $W$ we should notice the effects of slowdown less.
For that same reason, I would expect that worker rate go up for larger values of $W$.
\subsection{Dispatcher Rate:}
This experiment involves distributing a fixed amount of data among varying number of packets and sources. However, because the work per packet remains fairly small throughout ($W = 1$), we should not expect to see much opportunity for parallelization. If anything, the increased overhead from having to deal with more threads should mitigate any potential speedup. For that reason I think the ratio of $(n - 1) * T : runtime$ to shrink for larger values of $n$, even as $T$ becomes smaller.
\subsection{Speedup with Constant Load:}
Because larger values of $W$ imply more opportunity to parallelize the computation of checksums, for a given value of $n$, we should expect increased speedup for greater values of $W$. The same might be said for larger values of $n$ given a fixed value for $W$, in the sense that a greater number of worker threads might be able to work together more efficiently than a single thread. However, larger values of $n$ also imply larger amounts of overhead in managing threads and queues. Moreover, because we employ a constant packet generator, the amount of work each thread must perform is constant, so we should experience lesser opportunities for speedup even as we continue to process packets.
\\\\
Therefore, in comparing the observed speedup for different values of $W$, we should expect increased speedup for larger values of $W$. However, given a value of $W$, we should expect to possibly see some speedup for some values of $n$, if only accompanied by diminishing returns on speedup for larger values of $n$. The curves we might expect from these plots  would be concave downward in shape.
\subsection{Speedup with Uniform Load:}
We adopt the same reasoning from the prior experiment. However, because we employ a uniform packet generator, the amount of work each thread must perform is constantly increasing, so we should experience greater opportunities for speedup even as we continue to process packets.
\\\\
Therefore, in comparing the observed speedup for different values of $W$, we should expect increased speedup for larger values of $W$. For a given a value of $W$, we should expect to see something close to linear speedup for increasing values of $n$.

\subsection{Speedup with Exponentially Distributed Load:}
We adopt the same reasoning from the prior experiment. However, because we employ a exponential packet generator, the amount of work each thread must perform is constantly increasing at an exponential rate, so we should experience even greater opportunities for speedup even as we continue to process packets.
\\\\
Therefore, in comparing the observed speedup for different values of $W$, we should expect increased speedup for larger values of $W$. For a given a value of $W$, we should expect to see something linear speedup for increasing values of $n$, if only because the advantage of using $n - 1$ times as many threads in the parallel version than in the serial version will make itself even more apparent due to the exponential increase in work to be done.
\end{document}
